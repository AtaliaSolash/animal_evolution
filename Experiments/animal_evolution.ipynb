{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:09.783277Z",
     "iopub.status.busy": "2025-08-27T11:49:09.783019Z",
     "iopub.status.idle": "2025-08-27T11:49:13.187186Z",
     "shell.execute_reply": "2025-08-27T11:49:13.186566Z",
     "shell.execute_reply.started": "2025-08-27T11:49:09.783256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import csv\n",
    "import itertools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "from torchvision import transforms\n",
    "from contextlib import nullcontext\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, recall_score\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "matplotlib.use('Agg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:46:00.771287Z",
     "iopub.status.busy": "2025-08-27T11:46:00.770884Z",
     "iopub.status.idle": "2025-08-27T11:47:13.652049Z",
     "shell.execute_reply": "2025-08-27T11:47:13.651332Z",
     "shell.execute_reply.started": "2025-08-27T11:46:00.771265Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:16.684570Z",
     "iopub.status.busy": "2025-08-27T11:49:16.684161Z",
     "iopub.status.idle": "2025-08-27T11:49:16.718128Z",
     "shell.execute_reply": "2025-08-27T11:49:16.717217Z",
     "shell.execute_reply.started": "2025-08-27T11:49:16.684549Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T09:38:15.877167Z",
     "iopub.status.busy": "2025-08-20T09:38:15.876436Z",
     "iopub.status.idle": "2025-08-20T09:38:15.882932Z",
     "shell.execute_reply": "2025-08-20T09:38:15.882125Z",
     "shell.execute_reply.started": "2025-08-20T09:38:15.877141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_images(image_paths, cla):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    for i, path in enumerate(image_paths):     # Iterate over the image paths and display each image\n",
    "        image = mpimg.imread(path)\n",
    "        parts = path.split(\"/\")\n",
    "\n",
    "        family = parts[2]  # 'family'\n",
    "        animal = parts[4]\n",
    "        animal = animal[:-4]\n",
    "        axes[i].imshow(image, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].text(0.5, -0.15, f\"{family} â€“ {animal}\", size=9, ha='center', va='top',transform=axes[i].transAxes)\n",
    "    fig.suptitle(f\"Similarity: {cla}\", fontsize=16)     # Set a title indicating the label\n",
    "    plt.savefig(f\"data_preprocessing/Class_{cla}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:19.915345Z",
     "iopub.status.busy": "2025-08-27T11:49:19.914639Z",
     "iopub.status.idle": "2025-08-27T11:49:19.920729Z",
     "shell.execute_reply": "2025-08-27T11:49:19.919865Z",
     "shell.execute_reply.started": "2025-08-27T11:49:19.915311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_dataloaders(train_dataset, val_dataset, batch_size, num_workers=2, pin_memory=True, sampler=None):\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T08:43:09.264069Z",
     "iopub.status.busy": "2025-08-25T08:43:09.263300Z",
     "iopub.status.idle": "2025-08-25T08:43:09.269129Z",
     "shell.execute_reply": "2025-08-25T08:43:09.268158Z",
     "shell.execute_reply.started": "2025-08-25T08:43:09.264045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_grid_search_results_to_csv(results, csv_path):\n",
    "    \"\"\"\n",
    "    results: list of dicts with params + metrics\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to save.\")\n",
    "        return\n",
    "    fieldnames = list(results[0].keys())\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in results:\n",
    "            writer.writerow(row)\n",
    "    print(f\"Saved grid search results to {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:27.437081Z",
     "iopub.status.busy": "2025-08-27T11:49:27.436766Z",
     "iopub.status.idle": "2025-08-27T11:49:27.444863Z",
     "shell.execute_reply": "2025-08-27T11:49:27.444245Z",
     "shell.execute_reply.started": "2025-08-27T11:49:27.437057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, roots=None):\n",
    "        self.df = df\n",
    "        self.roots = roots or [\n",
    "            \"/kaggle/input/images-data\",\n",
    "            \"/kaggle/input/validation-set\",\n",
    "            \"/kaggle/input/test-set\",\n",
    "        ]\n",
    "        self.transform = transform if transform is not None else transforms.Compose([\n",
    "            transforms.Resize((244, 244)),\n",
    "            transforms.Grayscale(num_output_channels=3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _resolve_path(self, rel_path: str):\n",
    "        for r in self.roots:\n",
    "            p = os.path.join(r, rel_path)\n",
    "            if os.path.exists(p):\n",
    "                return p\n",
    "        raise FileNotFoundError(f\"Could not find {rel_path} in any of: {self.roots}\")\n",
    "\n",
    "    def _load_img(self, path: str):\n",
    "        return Image.open(path)\n",
    "        \n",
    "    def __getitem__(self, idx):# Retrieve paths to the images and their label from the DataFrame\n",
    "        # Open and apply transformations to the images\n",
    "        img1_path = self.df.iloc[idx]['image1']\n",
    "        img2_path = self.df.iloc[idx]['image2']\n",
    "\n",
    "        p1 = self._resolve_path(img1_path)\n",
    "        p2 = self._resolve_path(img2_path)\n",
    "        img1 = self._load_img(p1)\n",
    "        img2 = self._load_img(p2)\n",
    "            \n",
    "        img1 = self.transform(img1)\n",
    "        img2 = self.transform(img2)\n",
    "\n",
    "        label = torch.tensor(self.df.iloc[idx]['similarity_class'])\n",
    "        label = label.clone().detach().to(torch.float32)\n",
    "        return img1, img2, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:32.618940Z",
     "iopub.status.busy": "2025-08-27T11:49:32.618621Z",
     "iopub.status.idle": "2025-08-27T11:49:32.943401Z",
     "shell.execute_reply": "2025-08-27T11:49:32.942603Z",
     "shell.execute_reply.started": "2025-08-27T11:49:32.618917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import clip \n",
    "\n",
    "class SiameseClassificationCLIP(nn.Module):\n",
    "    \"\"\"\n",
    "    Siamese classifier using CLIP image encoder as the backbone.\n",
    "\n",
    "    - Backbone: CLIP model\n",
    "    - Pairwise head takes [z1, z2, |z1-z2|, z1*z2] -> logits (num_classes).\n",
    "      For multi-class use CrossEntropyLoss (targets 0-4).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        clip_name=\"ViT-B/32\",\n",
    "        device=None,\n",
    "        freeze_backbone=True,\n",
    "        pair_hidden1=1024,\n",
    "        pair_hidden2=512,\n",
    "        dropout=0.2,\n",
    "        use_batchnorm=True,\n",
    "        num_classes=5,\n",
    "        normalize_embeds=True,\n",
    "        jit=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Select device automatically if not provided\n",
    "        if device is None:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "        # Load CLIP model + its preprocessing pipeline\n",
    "        self.clip_model, self.preprocess = clip.load(clip_name, device=self.device, jit=jit)\n",
    "        self.clip_model.eval()  # encoder is usually used in eval mode\n",
    "\n",
    "        # Optionally freeze CLIP\n",
    "        if freeze_backbone:\n",
    "            for p in self.clip_model.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # Feature dimension (512 for ViT-B/32/RN50 etc.; accessed from model)\n",
    "        if hasattr(self.clip_model.visual, \"output_dim\"):\n",
    "            feat_dim = self.clip_model.visual.output_dim\n",
    "        else:\n",
    "            # Fallback (ViT-B/32, RN50 typically 512)\n",
    "            feat_dim = 512\n",
    "\n",
    "        self.normalize_embeds = normalize_embeds\n",
    "\n",
    "        # Pairwise head\n",
    "        pair_in = 4 * feat_dim\n",
    "        layers = []\n",
    "        # FC1\n",
    "        layers.append(nn.Linear(pair_in, pair_hidden1))\n",
    "        if use_batchnorm:\n",
    "            layers.append(nn.BatchNorm1d(pair_hidden1))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "        # FC2\n",
    "        layers.append(nn.Linear(pair_hidden1, pair_hidden2))\n",
    "        if use_batchnorm:\n",
    "            layers.append(nn.BatchNorm1d(pair_hidden2))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "        # FC3 -> logits\n",
    "        layers.append(nn.Linear(pair_hidden2, num_classes))\n",
    "\n",
    "        self.head = nn.Sequential(*layers)\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        x: preprocessed images (use self.preprocess on PIL images), shape [B, 3, H, W]\n",
    "        Returns: float32 features [B, D]\n",
    "        \"\"\"\n",
    "        # Ensure tensors live on the same device as the model\n",
    "        x = x.to(self.device)\n",
    "\n",
    "        # Match CLIP dtype (fp16 on CUDA, fp32 on CPU)\n",
    "        if x.dtype != self.clip_model.dtype:\n",
    "            x = x.to(dtype=self.clip_model.dtype)\n",
    "\n",
    "        # If the backbone is frozen, you can safely skip grads\n",
    "        with torch.no_grad() if not any(p.requires_grad for p in self.clip_model.parameters()) else torch.enable_grad():\n",
    "            z = self.clip_model.encode_image(x)  # [B, D]\n",
    "\n",
    "        if self.normalize_embeds:\n",
    "            z = z / z.norm(dim=-1, keepdim=True).clamp_min(1e-6)\n",
    "\n",
    "        # Head is in float32 for numeric stability\n",
    "        return z.float()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.encode(x1)  # [B, D]\n",
    "        z2 = self.encode(x2)  # [B, D]\n",
    "        feat = torch.cat([z1, z2, torch.abs(z1 - z2), z1 * z2], dim=1)  # [B, 4D]\n",
    "        logits = self.head(feat)  # [B, num_classes]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:37.201948Z",
     "iopub.status.busy": "2025-08-27T11:49:37.201214Z",
     "iopub.status.idle": "2025-08-27T11:49:37.208419Z",
     "shell.execute_reply": "2025-08-27T11:49:37.207660Z",
     "shell.execute_reply.started": "2025-08-27T11:49:37.201921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, loss_fn, device=\"cuda\", is_logits=True):\n",
    "    model.eval()\n",
    "    sum_loss, total = 0.0, 0\n",
    "    all_probs, all_preds, all_targets = [], [], []\n",
    "\n",
    "    for img1, img2, label in dataloader:\n",
    "        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "\n",
    "        outputs = model(img1, img2)\n",
    "\n",
    "        loss = loss_fn(outputs, label.long())\n",
    "        probs = F.softmax(outputs, dim=1)              # [B, K]\n",
    "        preds = probs.argmax(dim=1)                   # [B]\n",
    "        targets = label.long()\n",
    "\n",
    "        sum_loss += loss.item()\n",
    "        total += 1\n",
    "\n",
    "        all_probs.append(probs.detach().cpu())\n",
    "        all_preds.append(preds.detach().cpu())\n",
    "        all_targets.append(targets.detach().cpu())\n",
    "\n",
    "    avg_loss = sum_loss / max(1, total)\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    bal_acc = accuracy_score(all_targets, all_preds)\n",
    "    recalls = recall_score(all_targets, all_preds, average=None)  # per class\n",
    "    recall = recall_score(all_targets, all_preds)  \n",
    "\n",
    "    return avg_loss, f1, bal_acc, recall, recalls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:41.914505Z",
     "iopub.status.busy": "2025-08-27T11:49:41.913739Z",
     "iopub.status.idle": "2025-08-27T11:49:41.924314Z",
     "shell.execute_reply": "2025-08-27T11:49:41.923648Z",
     "shell.execute_reply.started": "2025-08-27T11:49:41.914478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model,\n",
    "    dataloader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    device=\"cuda\",\n",
    "    is_logits=True,              # True if model outputs raw logits\n",
    "    scaler=None,                 # torch.cuda.amp.GradScaler() or None\n",
    "    grad_clip=None,              # e.g., 1.0 or None\n",
    "    scheduler=None,              # optional LR scheduler\n",
    "    scheduler_step=\"epoch\",      # \"epoch\" or \"step\"\n",
    "    accumulation_steps=1,        # gradient accumulation\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains `model` for one epoch on `dataloader`.\n",
    "\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    sum_loss, n_steps = 0.0, 0\n",
    "    all_probs, all_preds, all_targets = [], [], []\n",
    "\n",
    "    # New AMP API\n",
    "    use_amp = (scaler is not None) and torch.cuda.is_available() and str(device).startswith(\"cuda\")\n",
    "    autocast_ctx = (lambda: torch.amp.autocast(\"cuda\", enabled=use_amp)) if use_amp else (lambda: nullcontext())\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for step, (img1, img2, label) in enumerate(progress_bar):\n",
    "        img1 = img1.to(device, non_blocking=True)\n",
    "        img2 = img2.to(device, non_blocking=True)\n",
    "        label  = label.to(device, non_blocking=True)\n",
    "\n",
    "        with autocast_ctx():\n",
    "            outputs = model(img1, img2)\n",
    "            loss = loss_fn(outputs, label.long())\n",
    "            loss_to_backprop = loss / accumulation_steps\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss_to_backprop).backward()\n",
    "        else:\n",
    "            loss_to_backprop.backward()\n",
    "\n",
    "        # Gradient step (with accumulation)\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            if grad_clip is not None:\n",
    "                if use_amp:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "            if use_amp:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            if scheduler is not None and scheduler_step == \"step\":\n",
    "                scheduler.step()\n",
    "\n",
    "        # logging stats\n",
    "        sum_loss += loss.item()\n",
    "        n_steps += 1\n",
    "        with torch.no_grad():\n",
    "            probs = F.softmax(outputs, dim=1).detach().cpu()\n",
    "            preds = probs.argmax(dim=1)\n",
    "            all_probs.append(probs)\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(label.cpu())\n",
    "\n",
    "        avg_loss = sum_loss / max(1, n_steps)\n",
    "        progress_bar.set_postfix({\"loss\": f\"{avg_loss:.4f}\"})\n",
    "\n",
    "    if scheduler is not None and scheduler_step == \"epoch\":\n",
    "        scheduler.step()\n",
    "\n",
    "    # Concatenate all predictions\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    avg_loss = sum_loss / max(1, n_steps)\n",
    "    \n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    bal_acc = accuracy_score(all_targets, all_preds)\n",
    "    recalls = recall_score(all_targets, all_preds, average=None)  # per class\n",
    "    recall = recall_score(all_targets, all_preds)  \n",
    "\n",
    "    return avg_loss, f1, bal_acc, recall, recalls \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:45.986262Z",
     "iopub.status.busy": "2025-08-27T11:49:45.985668Z",
     "iopub.status.idle": "2025-08-27T11:49:46.158283Z",
     "shell.execute_reply": "2025-08-27T11:49:46.157718Z",
     "shell.execute_reply.started": "2025-08-27T11:49:45.986238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/pairs-csv/train_animal_similarity_pairs.csv')\n",
    "\n",
    "val_df = pd.read_csv('/kaggle/input/pairs-csv/val_animal_similarity_pairs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "target_col = \"similarity_class\" \n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "\n",
    "# Train distribution\n",
    "train_counts = train_df[target_col].value_counts().sort_index()\n",
    "axes[0].bar(train_counts.index.astype(str), train_counts.values, color=\"skyblue\", edgecolor=\"black\")\n",
    "axes[0].set_title(\"Train set similarity distribution\")\n",
    "axes[0].set_xlabel(\"Similarity class\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "# Val distribution\n",
    "val_counts = val_df[target_col].value_counts().sort_index()\n",
    "axes[1].bar(val_counts.index.astype(str), val_counts.values, color=\"lightgreen\", edgecolor=\"black\")\n",
    "axes[1].set_title(\"Validation set similarity distribution\")\n",
    "axes[1].set_xlabel(\"Similarity class\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"similarity_distribution.png\", dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:51.757323Z",
     "iopub.status.busy": "2025-08-27T11:49:51.756713Z",
     "iopub.status.idle": "2025-08-27T11:49:51.782248Z",
     "shell.execute_reply": "2025-08-27T11:49:51.781631Z",
     "shell.execute_reply.started": "2025-08-27T11:49:51.757299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Count per class\n",
    "counts = train_df['similarity_class'].value_counts().sort_index()\n",
    "print(counts)\n",
    "\n",
    "# Target = count of class '4'\n",
    "n_per_class = int(counts.get(4, 0))\n",
    "print(\"Target per class:\", n_per_class)\n",
    "\n",
    "# Downsample each class \n",
    "balanced_train_df = (\n",
    "    train_df.groupby('similarity_class', group_keys=False)\n",
    "            .apply(lambda g: g.sample(n=min(len(g), n_per_class), random_state=42))\n",
    "            .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(balanced_train_df['similarity_class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:54.726400Z",
     "iopub.status.busy": "2025-08-27T11:49:54.725928Z",
     "iopub.status.idle": "2025-08-27T11:49:54.740960Z",
     "shell.execute_reply": "2025-08-27T11:49:54.740165Z",
     "shell.execute_reply.started": "2025-08-27T11:49:54.726376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Count per class\n",
    "counts = val_df['similarity_class'].value_counts().sort_index()\n",
    "print(counts)\n",
    "\n",
    "# Target = count of class '4'\n",
    "n_per_class = int(counts.get(4, 0))\n",
    "print(\"Target per class:\", n_per_class)\n",
    "\n",
    "balanced_val_df = (\n",
    "    val_df.groupby('similarity_class', group_keys=False)\n",
    "            .apply(lambda g: g.sample(n=min(len(g), n_per_class), random_state=42))\n",
    "            .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(balanced_val_df['similarity_class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:49:57.881917Z",
     "iopub.status.busy": "2025-08-27T11:49:57.881626Z",
     "iopub.status.idle": "2025-08-27T11:49:57.885771Z",
     "shell.execute_reply": "2025-08-27T11:49:57.885035Z",
     "shell.execute_reply.started": "2025-08-27T11:49:57.881896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(balanced_train_df)\n",
    "val_dataset = MyDataset(balanced_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Examples with score 0\n",
    "for idx, row in train_df[train_df['similarity_class'] == 0].head(1).iterrows():\n",
    "    display_images([f\"data_preprocessing/{row['image1']}\", f\"data_preprocessing/{row['image2']}\"], row['similarity_class'])\n",
    "\n",
    "for idx, row in train_df[train_df['similarity_class'] == 4].head(1).iterrows():\n",
    "    display_images([f\"data_preprocessing/{row['image1']}\", f\"data_preprocessing/{row['image2']}\"], row['similarity_class'])\n",
    "\n",
    "for idx, row in train_df[train_df['similarity_class'] == 3].head(1).iterrows():\n",
    "    display_images([f\"data_preprocessing/{row['image1']}\", f\"data_preprocessing/{row['image2']}\"], row['similarity_class'])\n",
    "\n",
    "for idx, row in train_df[train_df['similarity_class'] == 2].head(1).iterrows():\n",
    "    display_images([f\"data_preprocessing/{row['image1']}\", f\"data_preprocessing/{row['image2']}\"], row['similarity_class'])\n",
    "\n",
    "for idx, row in train_df[train_df['similarity_class'] == 1].head(1).iterrows():\n",
    "    display_images([f\"data_preprocessing/{row['image1']}\", f\"data_preprocessing/{row['image2']}\"], row['similarity_class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T08:40:37.978364Z",
     "iopub.status.busy": "2025-08-25T08:40:37.978136Z",
     "iopub.status.idle": "2025-08-25T08:40:37.995663Z",
     "shell.execute_reply": "2025-08-25T08:40:37.994837Z",
     "shell.execute_reply.started": "2025-08-25T08:40:37.978347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# choose a stable place on Kaggle\n",
    "CSV_PATH = \"/kaggle/working/results.csv\"\n",
    "\n",
    "FIELDNAMES = [\n",
    "    \"experiment_id\", \"timestamp\",\n",
    "    \"clip_name\", \"freeze_backbone\",\n",
    "    \"learning_rate\", \"weight_decay\",\n",
    "    \"batch_size\", \"dropout\", \"hidden_size\",\n",
    "    \"scheduler_type\",\n",
    "    \"epochs\", \"best_epoch\",\n",
    "    \"train_loss\", \"train_f1\", \"train_bal_acc\", \"train_recall\",\n",
    "    \"val_loss\", \"val_f1\", \"val_bal_acc\", \"val_recall\",\n",
    "]\n",
    "\n",
    "def save_result_row(row: dict, csv_path: str = CSV_PATH, fieldnames=FIELDNAMES):\n",
    "    os.makedirs(os.path.dirname(csv_path) or \".\", exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    # keep only known fields; fill missing with \"\"\n",
    "    row_to_write = {k: row.get(k, \"\") for k in fieldnames}\n",
    "\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row_to_write)\n",
    "        f.flush()\n",
    "        os.fsync(f.fileno())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T07:26:18.839827Z",
     "iopub.status.busy": "2025-08-22T07:26:18.839304Z",
     "iopub.status.idle": "2025-08-22T07:26:18.856721Z",
     "shell.execute_reply": "2025-08-22T07:26:18.855986Z",
     "shell.execute_reply.started": "2025-08-22T07:26:18.839805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_grid_search_siamese(\n",
    "    grid, grid_names,\n",
    "    train_dataset, val_dataset,\n",
    "    device=\"cuda\",\n",
    "    freeze_backbone=False,\n",
    "    epochs=5,\n",
    "    early_stopping_patience=None,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    accumulation_steps=1,\n",
    "    grad_clip=1.0,\n",
    "    use_amp=True,\n",
    "    scheduler_factory=None,\n",
    "    save_best_model_dir=None,\n",
    "    sampler=None                \n",
    "):\n",
    "    results = []\n",
    "    total_combos = len(grid)\n",
    "\n",
    "    # Safer default for pin_memory\n",
    "    pin_memory = bool(pin_memory and (device == \"cuda\" and torch.cuda.is_available()))\n",
    "\n",
    "    for i, combo in enumerate(grid):\n",
    "        params = dict(zip(grid_names, combo))\n",
    "        print(f\"\\n=== Combo {i+1}/{total_combos}: {params}\")\n",
    "\n",
    "        # Build CLIP-based model\n",
    "        model = SiameseClassificationCLIP(\n",
    "            clip_name=params[\"clip_name\"],\n",
    "            device=device,\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            pair_hidden1=max(2 * params[\"hidden_size\"], params[\"hidden_size\"]),\n",
    "            pair_hidden2=params[\"hidden_size\"],\n",
    "            dropout=params[\"dropout\"],\n",
    "            use_batchnorm=True,\n",
    "            num_classes=5,              \n",
    "            normalize_embeds=True,\n",
    "            jit=False,\n",
    "        ).to(device)\n",
    "\n",
    "        if not freeze_backbone:\n",
    "            model.clip_model.float()\n",
    "            for p in model.clip_model.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "        \n",
    "        # Make sure datasets use CLIP's preprocess\n",
    "        preprocess = model.preprocess\n",
    "        if hasattr(train_dataset, \"set_transform\"):\n",
    "            train_dataset.set_transform(preprocess)\n",
    "        elif hasattr(train_dataset, \"transform\"):\n",
    "            train_dataset.transform = preprocess\n",
    "        if hasattr(val_dataset, \"set_transform\"):\n",
    "            val_dataset.set_transform(preprocess)\n",
    "        elif hasattr(val_dataset, \"transform\"):\n",
    "            val_dataset.transform = preprocess\n",
    "\n",
    "        # DataLoaders \n",
    "        train_loader, val_loader = make_dataloaders(\n",
    "            train_dataset, val_dataset,\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "            sampler=sampler\n",
    "        )\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss()  # multi-class \n",
    "        is_logits = True\n",
    "\n",
    "        optim_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            optim_params,\n",
    "            lr=params[\"learning_rate\"],\n",
    "            weight_decay=params[\"weight_decay\"]  \n",
    "        )\n",
    "        \n",
    "        # Build scheduler \n",
    "        if params[\"scheduler_type\"] == \"onecycle\":\n",
    "            steps_per_epoch = max(1, len(train_loader))\n",
    "            scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=params[\"learning_rate\"],\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                pct_start=0.1,\n",
    "                anneal_strategy=\"cos\"\n",
    "            )\n",
    "        elif params[\"scheduler_type\"] == \"cosine\":\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer,\n",
    "                T_max=epochs,\n",
    "                eta_min=params[\"learning_rate\"] * 0.1\n",
    "            )\n",
    "        else:\n",
    "            scheduler = None\n",
    "\n",
    "        scheduler_step_mode = \"step\" if params[\"scheduler_type\"] == \"onecycle\" else \"epoch\"\n",
    "            \n",
    "        amp_enabled = (use_amp and torch.cuda.is_available() and str(device).startswith(\"cuda\"))\n",
    "        scaler = torch.amp.GradScaler('cuda', enabled=amp_enabled)\n",
    "        \n",
    "\n",
    "        # ---- Train loop ----\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            t0 = time.time()\n",
    "            train_loss, train_macro_f1, train_bal_acc, train_recall, train_recalls = train_one_epoch(\n",
    "                model, train_loader, optimizer, loss_fn,\n",
    "                device=device, is_logits=is_logits,\n",
    "                scaler=scaler, grad_clip=grad_clip,\n",
    "                scheduler=scheduler, scheduler_step=scheduler_step_mode,\n",
    "                accumulation_steps=accumulation_steps\n",
    "            )\n",
    "            val_loss, val_macro_f1, val_bal_acc, val_recall, val_recalls = evaluate(\n",
    "                model, val_loader, loss_fn,\n",
    "                device=device, is_logits=is_logits\n",
    "            )\n",
    "            dt = time.time() - t0\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch:02d}/{epochs} | \"\n",
    "                f\"train_loss {train_loss:.4f} | train_macro_f1 {train_macro_f1:.4f} | train_bal_acc {train_bal_acc:.4f} | \"\n",
    "                f\"val_loss {val_loss:.4f} | val_macro_f1 {val_macro_f1:.4f} | val_bal_acc {val_bal_acc:.4f} | \"\n",
    "                f\"val_recall {val_recall:.4f} | val_recalls {val_recalls} | {dt:.1f}s\"\n",
    "            )\n",
    "\n",
    "        best_payload = {\n",
    "        \"experiment_id\": i+1,\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"clip_name\": params[\"clip_name\"],\n",
    "        \"freeze_backbone\": freeze_backbone,\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"weight_decay\": params.get(\"weight_decay\", 1e-4),\n",
    "        \"batch_size\": params[\"batch_size\"],\n",
    "        \"dropout\": params[\"dropout\"],\n",
    "        \"hidden_size\": params[\"hidden_size\"],\n",
    "        \"scheduler_type\": params.get(\"scheduler_type\", \"none\"),\n",
    "        \"epochs\": epochs,\n",
    "        \"best_epoch\": epochs,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_f1\": train_macro_f1,\n",
    "        \"train_bal_acc\": train_bal_acc,\n",
    "        \"train_recall\": train_recall,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_f1\": val_macro_f1,\n",
    "        \"val_bal_acc\": val_bal_acc,\n",
    "        \"val_recall\": val_recall,\n",
    "        }\n",
    "        save_result_row(best_payload)\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-19T21:24:33.496Z",
     "iopub.execute_input": "2025-08-19T11:08:36.268635Z",
     "iopub.status.busy": "2025-08-19T11:08:36.268353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "common = {\n",
    "    \"learning_rate\":  [1e-3, 5e-4, 3e-4],\n",
    "    \"batch_size\":     [8, 16],\n",
    "    \"dropout\":        [0.1, 0.3, 0.5],\n",
    "    \"hidden_size\":    [128, 256, 512],\n",
    "    \"weight_decay\":   [1e-4, 5e-5],\n",
    "    \"scheduler_type\": [\"none\", \"onecycle\", \"cosine\"],\n",
    "}\n",
    "\n",
    "# RUN 1: ViT-B/32 \n",
    "param_grid_1 = {\"clip_name\": [\"ViT-B/32\"], **common}\n",
    "grid_names_1 = list(param_grid_1.keys())\n",
    "grid_1 = list(product(*param_grid_1.values()))\n",
    "print(\"Run 1 combos:\", len(grid_1))\n",
    "\n",
    "results_1 = run_grid_search_siamese(\n",
    "    grid=grid_1, grid_names=grid_names_1,\n",
    "    train_dataset=train_dataset, val_dataset=val_dataset,\n",
    "    device=device, freeze_backbone=True,\n",
    "    epochs=10, early_stopping_patience=3, num_workers=2,\n",
    "    pin_memory=True, accumulation_steps=1, grad_clip=1.0,\n",
    "    use_amp=True, scheduler_factory=None,\n",
    "    save_best_model_dir=\"grid_models_run1\", sampler=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-22T19:19:55.969Z",
     "iopub.execute_input": "2025-08-22T07:26:34.242789Z",
     "iopub.status.busy": "2025-08-22T07:26:34.242463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# RUN 2: ViT-L/14 \n",
    "common = {\n",
    "    \"learning_rate\":  [1e-3, 5e-4, 3e-4],\n",
    "    \"dropout\":        [0.3],  #0.1, 0.3, \n",
    "    \"hidden_size\":    [512],  #128, 256,\n",
    "    \"weight_decay\":   [1e-4, 5e-5],\n",
    "    \"scheduler_type\": [\"none\", \"onecycle\", \"cosine\"],\n",
    "}\n",
    "\n",
    "\n",
    "param_grid_2 = {\n",
    "    \"clip_name\":      [\"ViT-L/14\"],\n",
    "    \"learning_rate\":  common[\"learning_rate\"],\n",
    "    \"batch_size\":     [4],          # keep small for ViT-L/14\n",
    "    \"dropout\":        common[\"dropout\"],\n",
    "    \"hidden_size\":    common[\"hidden_size\"],\n",
    "    \"weight_decay\":   common[\"weight_decay\"],\n",
    "    \"scheduler_type\": common[\"scheduler_type\"],\n",
    "}\n",
    "grid_names_2 = list(param_grid_2.keys())\n",
    "grid_2 = list(product(*param_grid_2.values()))\n",
    "print(\"Run 2 combos:\", len(grid_2))\n",
    "\n",
    "results_2 = run_grid_search_siamese(\n",
    "    grid=grid_2, grid_names=grid_names_2,\n",
    "    train_dataset=train_dataset, val_dataset=val_dataset,\n",
    "    device=device, freeze_backbone=True,\n",
    "    epochs=10, early_stopping_patience=3, num_workers=2,\n",
    "    pin_memory=True, accumulation_steps=1, grad_clip=1.0,\n",
    "    use_amp=True, scheduler_factory=None,\n",
    "    save_best_model_dir=\"grid_models_run2\", sampler=None,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-21T18:44:53.054Z",
     "iopub.execute_input": "2025-08-21T06:48:26.833018Z",
     "iopub.status.busy": "2025-08-21T06:48:26.832226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# RUN 3: RN50 \n",
    "param_grid_3 = {\n",
    "    \"clip_name\":      [\"RN50\"],\n",
    "    \"learning_rate\":  [1e-3, 3e-4],\n",
    "    \"batch_size\":     [4, 6],          # keep small for ViT-L/14\n",
    "    \"dropout\":        [0.3, 0.5],\n",
    "    \"hidden_size\":    [256, 512],\n",
    "    \"weight_decay\":   [1e-4, 5e-5],\n",
    "    \"scheduler_type\": [\"none\", \"onecycle\", \"cosine\"],\n",
    "}\n",
    "\n",
    "grid_names = list(param_grid_3.keys())\n",
    "grid_3 = list(product(*param_grid_3.values()))\n",
    "print(\"Run 2 combos:\", len(grid_3))\n",
    "\n",
    "results_3 = run_grid_search_siamese(\n",
    "    grid=grid_3, grid_names=grid_names,\n",
    "    train_dataset=train_dataset, val_dataset=val_dataset,\n",
    "    device=device, freeze_backbone=True,\n",
    "    epochs=10, early_stopping_patience=3, num_workers=2,\n",
    "    pin_memory=True, accumulation_steps=1, grad_clip=1.0,\n",
    "    use_amp=True, scheduler_factory=None,\n",
    "    save_best_model_dir=\"grid_models_run3\", sampler=None,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:50:14.835782Z",
     "iopub.status.busy": "2025-08-27T11:50:14.835102Z",
     "iopub.status.idle": "2025-08-27T11:50:14.841184Z",
     "shell.execute_reply": "2025-08-27T11:50:14.840347Z",
     "shell.execute_reply.started": "2025-08-27T11:50:14.835758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# choose a stable place on Kaggle\n",
    "CSV_PATH = \"/kaggle/working/final_results2.csv\"\n",
    "\n",
    "FIELDNAMES = [\n",
    "    \"experiment_id\", \"timestamp\",\n",
    "    \"clip_name\", \"freeze_backbone\",\n",
    "    \"learning_rate\", \"weight_decay\",\n",
    "    \"batch_size\", \"dropout\", \"hidden_size\",\n",
    "    \"scheduler_type\",\n",
    "    \"epochs\", \"best_epoch\",\n",
    "    \"train_loss\", \"train_bal_acc\",\n",
    "    \"val_loss\", \"val_bal_acc\"\n",
    "]\n",
    "\n",
    "def save_result_row(row: dict, csv_path: str = CSV_PATH, fieldnames=FIELDNAMES):\n",
    "    os.makedirs(os.path.dirname(csv_path) or \".\", exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    # keep only known fields; fill missing with \"\"\n",
    "    row_to_write = {k: row.get(k, \"\") for k in fieldnames}\n",
    "\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row_to_write)\n",
    "        f.flush()\n",
    "        os.fsync(f.fileno())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:50:17.955593Z",
     "iopub.status.busy": "2025-08-27T11:50:17.955350Z",
     "iopub.status.idle": "2025-08-27T11:50:17.972724Z",
     "shell.execute_reply": "2025-08-27T11:50:17.972003Z",
     "shell.execute_reply.started": "2025-08-27T11:50:17.955576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_grid_search_siamese(\n",
    "    grid, grid_names,\n",
    "    train_dataset, val_dataset,\n",
    "    device=\"cuda\",\n",
    "    freeze_backbone=False,\n",
    "    epochs=5,\n",
    "    early_stopping_patience=None,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    accumulation_steps=1,\n",
    "    grad_clip=1.0,\n",
    "    use_amp=True,\n",
    "    scheduler_factory=None,\n",
    "    save_best_model_dir=None,\n",
    "    sampler=None                \n",
    "):\n",
    "\n",
    "    results = []\n",
    "    total_combos = len(grid)\n",
    "\n",
    "    # Safer default for pin_memory\n",
    "    pin_memory = bool(pin_memory and (device == \"cuda\" and torch.cuda.is_available()))\n",
    "\n",
    "    for i, combo in enumerate(grid):\n",
    "        params = dict(zip(grid_names, combo))\n",
    "        print(f\"\\n=== Combo {i+1}/{total_combos}: {params}\")\n",
    "\n",
    "        #Build CLIP-based model \n",
    "        model = SiameseClassificationCLIP(\n",
    "            clip_name=params[\"clip_name\"],\n",
    "            device=device,\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            pair_hidden1=max(2 * params[\"hidden_size\"], params[\"hidden_size\"]),\n",
    "            pair_hidden2=params[\"hidden_size\"],\n",
    "            dropout=params[\"dropout\"],\n",
    "            use_batchnorm=True,\n",
    "            num_classes=5,              \n",
    "            normalize_embeds=True,\n",
    "            jit=False,\n",
    "        ).to(device)\n",
    "\n",
    "        # If fine-tuning CLIP (optional block)\n",
    "        if not freeze_backbone:\n",
    "            model.clip_model.float()\n",
    "            for p in model.clip_model.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "        \n",
    "        # Make sure datasets use CLIP's preprocess\n",
    "        preprocess = model.preprocess\n",
    "        if hasattr(train_dataset, \"set_transform\"):\n",
    "            train_dataset.set_transform(preprocess)\n",
    "        elif hasattr(train_dataset, \"transform\"):\n",
    "            train_dataset.transform = preprocess\n",
    "        if hasattr(val_dataset, \"set_transform\"):\n",
    "            val_dataset.set_transform(preprocess)\n",
    "        elif hasattr(val_dataset, \"transform\"):\n",
    "            val_dataset.transform = preprocess\n",
    "\n",
    "        # DataLoaders \n",
    "        train_loader, val_loader = make_dataloaders(\n",
    "            train_dataset, val_dataset,\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "            sampler=sampler\n",
    "        )\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss()  # multi-class \n",
    "        is_logits = True\n",
    "\n",
    "        optim_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            optim_params,\n",
    "            lr=params[\"learning_rate\"],\n",
    "            weight_decay=params[\"weight_decay\"]  \n",
    "        )\n",
    "        \n",
    "        # Build scheduler from param\n",
    "        if params[\"scheduler_type\"] == \"onecycle\":\n",
    "            steps_per_epoch = max(1, len(train_loader))\n",
    "            scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=params[\"learning_rate\"],\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                pct_start=0.1,\n",
    "                anneal_strategy=\"cos\"\n",
    "            )\n",
    "        elif params[\"scheduler_type\"] == \"cosine\":\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer,\n",
    "                T_max=epochs,\n",
    "                eta_min=params[\"learning_rate\"] * 0.1\n",
    "            )\n",
    "        else:\n",
    "            scheduler = None\n",
    "\n",
    "        scheduler_step_mode = \"step\" if params[\"scheduler_type\"] == \"onecycle\" else \"epoch\"\n",
    "            \n",
    "        amp_enabled = (use_amp and torch.cuda.is_available() and str(device).startswith(\"cuda\"))\n",
    "        scaler = torch.amp.GradScaler('cuda', enabled=amp_enabled)\n",
    "        \n",
    "        best_acc = 0.0\n",
    "        best_epoch = 0\n",
    "        epochs_without_improve = 0\n",
    "        train_losses, train_acc, val_losses, val_acc = [], [], [], []\n",
    "        #  Train loop \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            t0 = time.time()\n",
    "            train_loss, train_macro_f1, train_bal_acc, train_recall, train_recalls = train_one_epoch(\n",
    "                model, train_loader, optimizer, loss_fn,\n",
    "                device=device, is_logits=is_logits,\n",
    "                scaler=scaler, grad_clip=grad_clip,\n",
    "                scheduler=scheduler, scheduler_step=scheduler_step_mode,\n",
    "                accumulation_steps=accumulation_steps\n",
    "            )\n",
    "            val_loss, val_macro_f1, val_bal_acc, val_recall, val_recalls = evaluate(\n",
    "                model, val_loader, loss_fn,\n",
    "                device=device, is_logits=is_logits\n",
    "            )\n",
    "            train_losses.append(train_loss)\n",
    "            train_acc.append(train_bal_acc)\n",
    "            val_losses.append(val_loss)\n",
    "            val_acc.append(val_bal_acc)\n",
    "            \n",
    "            dt = time.time() - t0\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch:02d}/{epochs} | \"\n",
    "                f\"train_loss {train_loss:.4f}  | train_acc {train_bal_acc:.4f} | \"\n",
    "                f\"val_loss {val_loss:.4f} | val_bal_acc {val_bal_acc:.4f} | {dt:.1f}s\"\n",
    "            )\n",
    "\n",
    "            improved = val_bal_acc > best_acc\n",
    "            if improved:\n",
    "                best_acc = val_bal_acc\n",
    "                best_epoch = epoch\n",
    "                epochs_without_improve = 0\n",
    "\n",
    "                # save best weights per combo\n",
    "                if save_best_model_dir:\n",
    "                    os.makedirs(save_best_model_dir, exist_ok=True)\n",
    "                    torch.save(\n",
    "                        {\"state_dict\": model.state_dict(), \"params\": params, \"epoch\": epoch},\n",
    "                        os.path.join(save_best_model_dir, f\"best_{i:03d}.pt\")\n",
    "                    )\n",
    "            else:\n",
    "                epochs_without_improve += 1\n",
    "                if early_stopping_patience is not None and epochs_without_improve >= early_stopping_patience:\n",
    "                    print(f\"Early stopping at epoch {epoch} (best at {best_epoch}, best_acc={best_acc:.4f})\")\n",
    "                    break\n",
    "\n",
    "\n",
    "        best_payload = {\n",
    "        \"experiment_id\": i+1,\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"clip_name\": params[\"clip_name\"],\n",
    "        \"freeze_backbone\": freeze_backbone,\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"weight_decay\": params.get(\"weight_decay\", 1e-4),\n",
    "        \"batch_size\": params[\"batch_size\"],\n",
    "        \"dropout\": params[\"dropout\"],\n",
    "        \"hidden_size\": params[\"hidden_size\"],\n",
    "        \"scheduler_type\": params.get(\"scheduler_type\", \"none\"),\n",
    "        \"epochs\": epochs,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"train_loss\": train_losses,\n",
    "        \"train_bal_acc\": train_acc,\n",
    "        \"val_loss\": val_losses,\n",
    "        \"val_bal_acc\": val_acc,\n",
    "        }\n",
    "        save_result_row(best_payload)\n",
    "\n",
    "    return model, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T10:00:03.039810Z",
     "iopub.status.busy": "2025-08-23T10:00:03.039036Z",
     "iopub.status.idle": "2025-08-23T10:08:40.835114Z",
     "shell.execute_reply": "2025-08-23T10:08:40.834346Z",
     "shell.execute_reply.started": "2025-08-23T10:00:03.039783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "common = {\n",
    "    \"learning_rate\":  [1e-3],\n",
    "    \"batch_size\":     [8],\n",
    "    \"dropout\":        [0.5],\n",
    "    \"hidden_size\":    [128],\n",
    "    \"weight_decay\":   [1e-4],\n",
    "    \"scheduler_type\": [\"onecycle\"],\n",
    "}\n",
    "\n",
    "# RUN 1: ViT-B/32  \n",
    "param_grid_1 = {\"clip_name\": [\"ViT-B/32\"], **common}\n",
    "grid_names_1 = list(param_grid_1.keys())\n",
    "grid_1 = list(product(*param_grid_1.values()))\n",
    "\n",
    "model1, results_1 = run_grid_search_siamese(\n",
    "    grid=grid_1, grid_names=grid_names_1,\n",
    "    train_dataset=train_dataset, val_dataset=val_dataset,\n",
    "    device=device, freeze_backbone=True,\n",
    "    epochs=20, early_stopping_patience=3, num_workers=0,\n",
    "    pin_memory=True, accumulation_steps=1, grad_clip=1.0,\n",
    "    use_amp=True, scheduler_factory=None,\n",
    "    save_best_model_dir=\"grid_models_run1\", sampler=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:50:30.684682Z",
     "iopub.status.busy": "2025-08-27T11:50:30.684407Z",
     "iopub.status.idle": "2025-08-27T12:36:32.459067Z",
     "shell.execute_reply": "2025-08-27T12:36:32.458006Z",
     "shell.execute_reply.started": "2025-08-27T11:50:30.684661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "common = {\n",
    "    \"learning_rate\":  [1e-3],\n",
    "    \"batch_size\":     [4],\n",
    "    \"dropout\":        [0.1],\n",
    "    \"hidden_size\":    [128],\n",
    "    \"weight_decay\":   [5e-5],\n",
    "    \"scheduler_type\": [\"onecycle\"],\n",
    "}\n",
    "\n",
    "param_grid_1 = {\"clip_name\": [\"ViT-L/14\"], **common}\n",
    "grid_names_1 = list(param_grid_1.keys())\n",
    "grid_1 = list(product(*param_grid_1.values()))\n",
    "\n",
    "model, results_1 = run_grid_search_siamese(\n",
    "    grid=grid_1, grid_names=grid_names_1,\n",
    "    train_dataset=train_dataset, val_dataset=val_dataset,\n",
    "    device=device, freeze_backbone=True,\n",
    "    epochs=20, early_stopping_patience=3, num_workers=2,\n",
    "    pin_memory=True, accumulation_steps=1, grad_clip=1.0,\n",
    "    use_amp=True, scheduler_factory=None,\n",
    "    save_best_model_dir=\"grid_models_run2\", sampler=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T11:26:20.982658Z",
     "iopub.status.busy": "2025-08-23T11:26:20.981967Z",
     "iopub.status.idle": "2025-08-23T11:32:41.617838Z",
     "shell.execute_reply": "2025-08-23T11:32:41.617043Z",
     "shell.execute_reply.started": "2025-08-23T11:26:20.982608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "param_grid_3 = {\n",
    "    \"clip_name\":      [\"RN50\"],\n",
    "    \"learning_rate\":  [1e-3],\n",
    "    \"batch_size\":     [6],          # keep small for ViT-L/14\n",
    "    \"dropout\":        [0.3],\n",
    "    \"hidden_size\":    [256],\n",
    "    \"weight_decay\":   [5e-5],\n",
    "    \"scheduler_type\": [\"onecycle\"],\n",
    "}\n",
    "\n",
    "grid_names = list(param_grid_3.keys())\n",
    "grid_3 = list(product(*param_grid_3.values()))\n",
    "print(\"Run 2 combos:\", len(grid_3))\n",
    "\n",
    "model3, results_3 = run_grid_search_siamese(\n",
    "    grid=grid_3, grid_names=grid_names,\n",
    "    train_dataset=train_dataset, val_dataset=val_dataset,\n",
    "    device=device, freeze_backbone=True,\n",
    "    epochs=20, early_stopping_patience=3, num_workers=2,\n",
    "    pin_memory=True, accumulation_steps=1, grad_clip=1.0,\n",
    "    use_amp=True, scheduler_factory=None,\n",
    "    save_best_model_dir=\"grid_models_run3\", sampler=None,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:46:49.343937Z",
     "iopub.status.busy": "2025-08-24T11:46:49.343370Z",
     "iopub.status.idle": "2025-08-24T11:46:49.347552Z",
     "shell.execute_reply": "2025-08-24T11:46:49.346716Z",
     "shell.execute_reply.started": "2025-08-24T11:46:49.343914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(balanced_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T09:32:56.740740Z",
     "iopub.status.busy": "2025-08-25T09:32:56.740416Z",
     "iopub.status.idle": "2025-08-25T09:32:56.845570Z",
     "shell.execute_reply": "2025-08-25T09:32:56.844841Z",
     "shell.execute_reply.started": "2025-08-25T09:32:56.740715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/pairs-csv/test_animal_similarity_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T09:33:01.972137Z",
     "iopub.status.busy": "2025-08-25T09:33:01.971531Z",
     "iopub.status.idle": "2025-08-25T09:33:01.989378Z",
     "shell.execute_reply": "2025-08-25T09:33:01.988321Z",
     "shell.execute_reply.started": "2025-08-25T09:33:01.972112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Count per class\n",
    "counts = test_df['similarity_class'].value_counts().sort_index()\n",
    "print(counts)\n",
    "\n",
    "# Target = count of class '4'\n",
    "n_per_class = int(counts.get(4, 0))\n",
    "print(\"Target per class:\", n_per_class)\n",
    "\n",
    "# Downsample each class to n_per_class (uses all class-4 rows)\n",
    "balanced_test_df = (\n",
    "    test_df.groupby('similarity_class', group_keys=False)\n",
    "            .apply(lambda g: g.sample(n=min(len(g), n_per_class), random_state=42))\n",
    "            .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(balanced_test_df['similarity_class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T09:33:05.776847Z",
     "iopub.status.busy": "2025-08-25T09:33:05.776570Z",
     "iopub.status.idle": "2025-08-25T09:33:05.781060Z",
     "shell.execute_reply": "2025-08-25T09:33:05.780348Z",
     "shell.execute_reply.started": "2025-08-25T09:33:05.776826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(balanced_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T09:37:37.573366Z",
     "iopub.status.busy": "2025-08-24T09:37:37.573055Z",
     "iopub.status.idle": "2025-08-24T09:37:50.215900Z",
     "shell.execute_reply": "2025-08-24T09:37:50.215263Z",
     "shell.execute_reply.started": "2025-08-24T09:37:37.573346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from /kaggle/input/best-model/best_ViT-L.pt (epoch=3)\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def build_model_from_params(params: dict):\n",
    "    # Build CLIP-based model \n",
    "    model = SiameseClassificationCLIP(\n",
    "            clip_name=params[\"clip_name\"],\n",
    "            device=device,\n",
    "            freeze_backbone=True,\n",
    "            pair_hidden1=max(2 * params[\"hidden_size\"], params[\"hidden_size\"]),\n",
    "            pair_hidden2=params[\"hidden_size\"],\n",
    "            dropout=params[\"dropout\"],\n",
    "            use_batchnorm=True,\n",
    "            num_classes=5,              # you had 5 classes in your head\n",
    "            normalize_embeds=True,\n",
    "            jit=False,\n",
    "        ).to(device)\n",
    "    return model\n",
    "\n",
    "def _strip_module_prefix(state_dict):\n",
    "    if not any(k.startswith(\"module.\") for k in state_dict.keys()):\n",
    "        return state_dict\n",
    "    new_sd = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_sd[k[len(\"module.\"):] if k.startswith(\"module.\") else k] = v\n",
    "    return new_sd\n",
    "\n",
    "def load_model_from_checkpoint(path, strict=True):\n",
    "    ckpt = torch.load(path, map_location=device)     # returns the dict you saved\n",
    "    params = ckpt.get(\"params\", {})                  # your hyperparams/config\n",
    "    epoch  = ckpt.get(\"epoch\", None)\n",
    "    model = build_model_from_params(params)\n",
    "    state_dict = _strip_module_prefix(ckpt[\"state_dict\"])\n",
    "    missing, unexpected = model.load_state_dict(state_dict, strict=strict)\n",
    "    if missing or unexpected:\n",
    "        print(\"load_state_dict note:\")\n",
    "        print(\"  missing keys   :\", missing)\n",
    "        print(\"  unexpected keys:\", unexpected)\n",
    "\n",
    "    model.to(device).eval()\n",
    "    print(f\"Loaded checkpoint from {path} (epoch={epoch})\")\n",
    "    return model, params, epoch\n",
    "\n",
    "CKPT = '/kaggle/input/best-model/best_ViT-L.pt'\n",
    "model, params, epoch = load_model_from_checkpoint(CKPT, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T09:33:25.151889Z",
     "iopub.status.busy": "2025-08-25T09:33:25.151332Z",
     "iopub.status.idle": "2025-08-25T09:33:25.156265Z",
     "shell.execute_reply": "2025-08-25T09:33:25.155597Z",
     "shell.execute_reply.started": "2025-08-25T09:33:25.151851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preprocess = model.preprocess\n",
    "\n",
    "if hasattr(train_dataset, \"set_transform\"):\n",
    "    train_dataset.set_transform(preprocess)\n",
    "elif hasattr(train_dataset, \"transform\"):\n",
    "    train_dataset.transform = preprocess\n",
    "\n",
    "if hasattr(test_dataset, \"set_transform\"):\n",
    "    test_dataset.set_transform(preprocess)\n",
    "elif hasattr(test_dataset, \"transform\"):\n",
    "    test_dataset.transform = preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T09:33:29.102388Z",
     "iopub.status.busy": "2025-08-25T09:33:29.101745Z",
     "iopub.status.idle": "2025-08-25T09:33:29.106355Z",
     "shell.execute_reply": "2025-08-25T09:33:29.105534Z",
     "shell.execute_reply.started": "2025-08-25T09:33:29.102362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T14:25:39.893460Z",
     "iopub.status.busy": "2025-08-23T14:25:39.892743Z",
     "iopub.status.idle": "2025-08-23T14:25:39.900585Z",
     "shell.execute_reply": "2025-08-23T14:25:39.899757Z",
     "shell.execute_reply.started": "2025-08-23T14:25:39.893437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def test_evaluate(model, dataloader, loss_fn, device=\"cuda\", is_logits=True):\n",
    "    model.eval()\n",
    "    sum_loss, total = 0.0, 0\n",
    "    all_probs, all_preds, all_targets = [], [], []\n",
    "\n",
    "    for img1, img2, label in dataloader:\n",
    "        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "\n",
    "        outputs = model(img1, img2)\n",
    "        loss = loss_fn(outputs, label.long())\n",
    "\n",
    "        probs = F.softmax(outputs, dim=1)   # [B, K]\n",
    "        preds = probs.argmax(dim=1)         # [B]\n",
    "        targets = label.long()\n",
    "\n",
    "        sum_loss += loss.item()\n",
    "        total += 1\n",
    "\n",
    "        all_probs.append(probs.detach().cpu())\n",
    "        all_preds.append(preds.detach().cpu())\n",
    "        all_targets.append(targets.detach().cpu())\n",
    "\n",
    "    avg_loss = sum_loss / max(1, total)\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    bal_acc  = accuracy_score(all_targets, all_preds)   \n",
    "    recalls  = recall_score(all_targets, all_preds, average=None)     # per-class\n",
    "    recall   = recall_score(all_targets, all_preds)  \n",
    "\n",
    "    n_classes = all_probs.shape[1]\n",
    "    cm = confusion_matrix(all_targets, all_preds, labels=list(range(n_classes)))\n",
    "\n",
    "    return avg_loss, f1, bal_acc, recall, recalls, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T14:25:45.392406Z",
     "iopub.status.busy": "2025-08-23T14:25:45.392094Z",
     "iopub.status.idle": "2025-08-23T14:26:31.546140Z",
     "shell.execute_reply": "2025-08-23T14:26:31.545163Z",
     "shell.execute_reply.started": "2025-08-23T14:25:45.392383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()  # multi-class \n",
    "is_logits = True\n",
    "test_loss, test_f1, test_bal_acc, test_recall, test_recalls, cm = test_evaluate(\n",
    "    model, test_loader, loss_fn,\n",
    "    device=device, is_logits=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T14:26:38.343142Z",
     "iopub.status.busy": "2025-08-23T14:26:38.342812Z",
     "iopub.status.idle": "2025-08-23T14:26:38.349604Z",
     "shell.execute_reply": "2025-08-23T14:26:38.348808Z",
     "shell.execute_reply.started": "2025-08-23T14:26:38.343119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def print_metrics(loss, f1, acc, recall, per_class_recalls, class_names=None):\n",
    "    if class_names is None:\n",
    "        class_names = [f\"class_{i}\" for i in range(len(per_class_recalls))]\n",
    "    print(f\"Loss: {loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | Recall: {recall:.4f}\")\n",
    "    for i, r in enumerate(per_class_recalls):\n",
    "        print(f\"  [{i}] {class_names[i]}: recall={r:.4f}\")\n",
    "\n",
    "def print_confusion_matrix_counts(cm, class_names=None):\n",
    "    if class_names is None:\n",
    "        class_names = [f\"class_{i}\" for i in range(cm.shape[0])]\n",
    "    header = \"pred  \" + \" \".join([f\"{n:>8}\" for n in class_names])\n",
    "    print(\"\\nConfusion Matrix (counts):\")\n",
    "    print(header)\n",
    "    for i, row in enumerate(cm):\n",
    "        print(f\"true {class_names[i]:>4} \" + \" \".join([f\"{v:8d}\" for v in row]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T14:26:42.766442Z",
     "iopub.status.busy": "2025-08-23T14:26:42.766114Z",
     "iopub.status.idle": "2025-08-23T14:26:42.770892Z",
     "shell.execute_reply": "2025-08-23T14:26:42.770205Z",
     "shell.execute_reply.started": "2025-08-23T14:26:42.766420Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6197 | Acc: 0.7420 | F1: 0.7315 | Recall: 0.7420\n",
      "  [0] Low: recall=0.9938\n",
      "  [1] Med-Low: recall=0.9136\n",
      "  [2] Med: recall=0.6296\n",
      "  [3] High: recall=0.3951\n",
      "  [4] Very High: recall=0.7778\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"Low\", \"Med-Low\", \"Med\", \"High\", \"Very High\"]  # edit to your labels\n",
    "print_metrics(test_loss, test_f1, test_bal_acc, test_recall, test_recalls, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T14:27:14.954101Z",
     "iopub.status.busy": "2025-08-23T14:27:14.953834Z",
     "iopub.status.idle": "2025-08-23T14:27:14.962316Z",
     "shell.execute_reply": "2025-08-23T14:27:14.961538Z",
     "shell.execute_reply.started": "2025-08-23T14:27:14.954081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names=None, normalize=False, title=None):\n",
    "    cm = np.asarray(cm)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(np.float64)\n",
    "        row_sums = cm.sum(axis=1, keepdims=True)\n",
    "        cm = np.divide(cm, np.maximum(row_sums, 1e-12))\n",
    "        fmt = \".2f\"\n",
    "    else:\n",
    "        fmt = \"d\" if np.issubdtype(cm.dtype, np.integer) else \".0f\"\n",
    "\n",
    "    if class_names is None:\n",
    "        class_names = [f\"class_{i}\" for i in range(cm.shape[0])]\n",
    "    elif len(class_names) != cm.shape[0]:\n",
    "        raise ValueError(\"len(class_names) must equal cm.shape[0]\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5), dpi=120)\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\", aspect=\"auto\")\n",
    "    ax.figure.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "    ax.set(\n",
    "        xticks=np.arange(cm.shape[1]),\n",
    "        yticks=np.arange(cm.shape[0]),\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        xlabel=\"Predicted label\",\n",
    "        ylabel=\"True label\",\n",
    "        title=title or (\"Confusion Matrix (normalized)\" if normalize else \"Confusion Matrix\")\n",
    "    )\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Text labels\n",
    "    thresh = (cm.max() + cm.min()) / 2.0 if cm.size else 0.5\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"CM.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T14:27:19.150417Z",
     "iopub.status.busy": "2025-08-23T14:27:19.150047Z",
     "iopub.status.idle": "2025-08-23T14:27:19.459567Z",
     "shell.execute_reply": "2025-08-23T14:27:19.458958Z",
     "shell.execute_reply.started": "2025-08-23T14:27:19.150395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, class_names=class_names, normalize=False, title=\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T13:09:44.827590Z",
     "iopub.status.busy": "2025-08-23T13:09:44.827315Z",
     "iopub.status.idle": "2025-08-23T13:09:44.833684Z",
     "shell.execute_reply": "2025-08-23T13:09:44.832959Z",
     "shell.execute_reply.started": "2025-08-23T13:09:44.827571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(Image(filename='/kaggle/working/CM.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explainability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T09:45:35.825231Z",
     "iopub.status.busy": "2025-08-25T09:45:35.824948Z",
     "iopub.status.idle": "2025-08-25T09:45:44.515420Z",
     "shell.execute_reply": "2025-08-25T09:45:44.514616Z",
     "shell.execute_reply.started": "2025-08-25T09:45:35.825211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!pip install grad_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T14:15:00.385275Z",
     "iopub.status.busy": "2025-08-27T14:15:00.384971Z",
     "iopub.status.idle": "2025-08-27T14:15:01.422934Z",
     "shell.execute_reply": "2025-08-27T14:15:01.422163Z",
     "shell.execute_reply.started": "2025-08-27T14:15:00.385252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import types\n",
    "import cv2\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "# 1) helpers ------------------------------------------------------------\n",
    "def preprocess_clip_image(img_path, img_size=224):\n",
    "    mean=(0.48145466, 0.4578275, 0.40821073)\n",
    "    std =(0.26862954, 0.26130258, 0.27577711)\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    pil = Image.open(img_path).convert(\"RGB\")\n",
    "    x = tfm(pil).unsqueeze(0)\n",
    "    return pil, x\n",
    "\n",
    "def overlay_heatmap(pil_img, cam, alpha=0.6):\n",
    "    img = np.array(pil_img)\n",
    "    heat = (cam * 255).astype(np.uint8)\n",
    "    heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)[:, :, ::-1]\n",
    "    heat = cv2.resize(heat, (img.shape[1], img.shape[0]))\n",
    "    return (alpha*heat + (1-alpha)*img).astype(np.uint8)\n",
    "\n",
    "def patch_grid_for(img_size, patch=14):\n",
    "    g = img_size // patch\n",
    "    return (g, g)\n",
    "\n",
    "# 2) Patch CLIP to expose/store attention weights \n",
    "def patch_residual_attention_block(block):\n",
    "    orig_attention = block.attention  # method on the block\n",
    "\n",
    "    def attention_with_weights(self, x: torch.Tensor):\n",
    "        # Same as CLIP, but request weights and store them.\n",
    "        self.attn_mask = self.attn_mask.to(dtype=x.dtype, device=x.device) if self.attn_mask is not None else None\n",
    "        out, w = self.attn(x, x, x, need_weights=True, attn_mask=self.attn_mask)\n",
    "        # Store attention probs on the attn module for hooks to read\n",
    "        self.attn.last_attn = w  # [B, heads, N, N]\n",
    "        return out\n",
    "\n",
    "    block.attention = types.MethodType(attention_with_weights, block)\n",
    "\n",
    "# 3) Rollout engine \n",
    "class ViTGradRollout:\n",
    "    def __init__(self, clip_siamese, use_last_k=6, use_grads=False):\n",
    "        self.model = clip_siamese.eval()\n",
    "        self.blocks = list(self.model.clip_model.visual.transformer.resblocks)\n",
    "        self.use_last_k = use_last_k\n",
    "        self.use_grads = use_grads\n",
    "        self.attns, self.attn_grads, self.hooks = [], [], []\n",
    "\n",
    "        # Hooks read attn probs that stored in patch_residual_attention_block\n",
    "        for blk in self.blocks:\n",
    "            attn = blk.attn\n",
    "\n",
    "            def fwd_hook(mod, inp, out):\n",
    "                w = getattr(mod, \"last_attn\", None)  # [B, H, N, N]\n",
    "                if w is not None:\n",
    "                    self.attns.append(w.mean(dim=1))  # average heads â†’ [B, N, N]\n",
    "\n",
    "            self.hooks.append(attn.register_forward_hook(fwd_hook))\n",
    "\n",
    "            if use_grads:\n",
    "                pass\n",
    "\n",
    "    def remove(self):\n",
    "        for h in self.hooks:\n",
    "            try: h.remove()\n",
    "            except: pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _norm(self, x):\n",
    "        x = x - x.min()\n",
    "        return x / (x.max() + 1e-8)\n",
    "\n",
    "    def __call__(self, x, score, patch_grid):\n",
    "        A_list = self.attns[-self.use_last_k:]\n",
    "        if len(A_list) == 0:\n",
    "            raise RuntimeError(\"No attention maps captured.\")\n",
    "\n",
    "        Hp, Wp = patch_grid\n",
    "        T = 1 + Hp*Wp\n",
    "        device = A_list[0].device\n",
    "        rollout = torch.eye(T, T, device=device)\n",
    "\n",
    "        for A in A_list:\n",
    "            A = A[0]  # B=1 -> [N,N]\n",
    "            A = A / (A.sum(-1, keepdim=True) + 1e-8)           # row-normalize\n",
    "            A = A + torch.eye(T, T, device=device)             # add residual\n",
    "            A = A / (A.sum(-1, keepdim=True) + 1e-8)           # renormalize\n",
    "            rollout = A @ rollout\n",
    "\n",
    "        patch = rollout[0, 1:].reshape(Hp, Wp)                  # drop CLS token\n",
    "        patch = self._norm(patch)\n",
    "\n",
    "        cam = torch.tensor(patch[None, None].cpu().numpy()).float()\n",
    "        cam = F.interpolate(cam, size=x.shape[-2:], mode=\"bilinear\", align_corners=False)[0, 0].cpu().numpy()\n",
    "        cam = self._norm(cam)\n",
    "        return cam\n",
    "\n",
    "# 4) Load your (Siamese) model that wraps CLIP\n",
    "clip_model = model  \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model = clip_model.eval().to(device)\n",
    "\n",
    "# Patch every CLIP block to store attn weights during forward\n",
    "for blk in clip_model.clip_model.visual.transformer.resblocks:\n",
    "    patch_residual_attention_block(blk)\n",
    "\n",
    "# 5) Inputs / paths\n",
    "left_path  = \"/kaggle/input/test-set/test/bovidae/Caprinae/Bighorn sheep head/000001.jpg\"\n",
    "right_path = \"/kaggle/input/test-set/test/caninae/Vulpini/blanford fox head/000005.jpg\"\n",
    "\n",
    "IMG_SIZE = 224                 # match your training size\n",
    "HpWp = patch_grid_for(IMG_SIZE, patch=14)  # ViT-L/14 , patch=14\n",
    "\n",
    "pilL, xL = preprocess_clip_image(left_path,  IMG_SIZE);  xL = xL.to(device)\n",
    "pilR, xR = preprocess_clip_image(right_path, IMG_SIZE);  xR = xR.to(device)\n",
    "\n",
    "# 6) Wrappers: explain LEFT given fixed RIGHT (and vice-versa)\n",
    "class LeftOnlyWrapper(torch.nn.Module):\n",
    "    def __init__(self, siamese_model, x_right_fixed):\n",
    "        super().__init__()\n",
    "        self.m  = siamese_model\n",
    "        self.xr = x_right_fixed  \n",
    "\n",
    "    def forward(self, x_left):\n",
    "        out = self.m(x_left, self.xr)  \n",
    "        vals, _ = out.max(dim=1) if out.ndim == 2 else (out.view(-1), None)\n",
    "        return vals  # [B]\n",
    "\n",
    "class RightOnlyWrapper(torch.nn.Module):\n",
    "    def __init__(self, siamese_model, x_left_fixed):\n",
    "        super().__init__()\n",
    "        self.m  = siamese_model\n",
    "        self.xl = x_left_fixed\n",
    "\n",
    "    def forward(self, x_right):\n",
    "        out = self.m(self.xl, x_right)\n",
    "        print(out)\n",
    "        vals, _ = out.max(dim=1) if out.ndim == 2 else (out.view(-1), None)\n",
    "        return vals\n",
    "\n",
    "wrapper_left  = LeftOnlyWrapper(clip_model, xR).to(device).eval()\n",
    "wrapper_right = RightOnlyWrapper(clip_model, xL).to(device).eval()\n",
    "\n",
    "# 7) Explain LEFT given RIGHT\n",
    "engine = ViTGradRollout(clip_model, use_last_k=47, use_grads=False)\n",
    "\n",
    "with torch.enable_grad():\n",
    "    score_left = wrapper_left(xL)     # [1]\n",
    "    score_left = score_left.squeeze() # scalar \n",
    "\n",
    "cam_left = engine(xL, score_left, patch_grid=HpWp)\n",
    "print('LEFT cam stats:', cam_left.min(), cam_left.max(), cam_left.mean())\n",
    "print('LEFT layers captured:', len(engine.attns))\n",
    "engine.remove()\n",
    "\n",
    "overlay_left = overlay_heatmap(pilL, cam_left, alpha=0.45)\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.subplot(1,2,1); plt.axis(\"off\"); plt.title(\"Left Image\"); plt.imshow(pilL)\n",
    "plt.subplot(1,2,2); plt.axis(\"off\"); plt.title(\"CAM explaining left (given right)\"); plt.imshow(overlay_left)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"gradcam_overlay_left.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# 8) Explain RIGHT given LEFT\n",
    "engine = ViTGradRollout(clip_model, use_last_k=47, use_grads=False)\n",
    "\n",
    "with torch.enable_grad():\n",
    "    score_right = wrapper_right(xR)   # [1]\n",
    "    score_right = score_right.squeeze()\n",
    "\n",
    "cam_right = engine(xR, score_right, patch_grid=HpWp)\n",
    "print('RIGHT cam stats:', cam_right.min(), cam_right.max(), cam_right.mean())\n",
    "print('RIGHT layers captured:', len(engine.attns))\n",
    "engine.remove()\n",
    "\n",
    "overlay_right = overlay_heatmap(pilR, cam_right, alpha=0.45)\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.subplot(1,2,1); plt.axis(\"off\"); plt.title(\"Right Image\"); plt.imshow(pilR)\n",
    "plt.subplot(1,2,2); plt.axis(\"off\"); plt.title(\"CAM explaining right (given left)\"); plt.imshow(overlay_right)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"gradcam_overlay_right.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8084010,
     "sourceId": 12786561,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8084038,
     "sourceId": 12786602,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8084070,
     "sourceId": 12786654,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8103834,
     "sourceId": 12815613,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8103854,
     "sourceId": 12815638,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8103871,
     "sourceId": 12815659,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8124154,
     "sourceId": 12844983,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8124824,
     "sourceId": 12845966,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8136334,
     "sourceId": 12863068,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
